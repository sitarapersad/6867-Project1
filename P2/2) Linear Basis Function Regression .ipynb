{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s consider the linear combination of basis function class of regression models.  We know how\n",
    "to get closed-form solutions for the maximum likelihood weight vector (see Bishop equation 3.15,\n",
    "Murphy section 7.2 and equation 7.16). We’ll use this problem to “benchmark” the gradient descent\n",
    "solution.\n",
    "\n",
    "\n",
    "We have provided you with a text file (curvefittingp2.txt) that has 11 data points for you to\n",
    "fit.  The function we used for generating these data is $ y(x) = \\cos(\\pi x) + 1.5 \\cos(2\\pi x)$, with a little\n",
    "added noise.  We have also given you code to read this data and some code illustrating how to\n",
    "generate plots, both in Python and Matlab.\n",
    "\n",
    "1.  Assume that we do not know the real basis for these points and want to try out a polynomial\n",
    "fitting.  Write a procedure for computing the maximum likelihood weight vector given (a) an\n",
    "array of 1-dimensional data points X, (b) a vector of Y values,  and (c) the value of M, the\n",
    "maximum order of a simple polynomial basis $\\phi_{0}(x) = 1 ,  \\phi_{1}(x) = x,  ..., \\phi_{M}(x) = x^{M}$ .\n",
    "Test your solution by replicating the plots above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
