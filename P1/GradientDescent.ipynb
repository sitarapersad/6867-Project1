{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np\n",
    "import pandas \n",
    "import gradientDescent as gd\n",
    "import loadParametersP1 as params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implement a basic gradient descent procedure to minimize scalar functions of a vector argument.\n",
    "Write it generically, so that you can easily specify the objective function and the function\n",
    "to compute the gradient. You should be able to specify the initial guess, the step size (or learning\n",
    "rate) and the convergence criterion (e.g., a threshold such that the algorithm terminates\n",
    "when the difference in objective function value on two successive steps is below this threshold\n",
    "or when the norm of the gradient is below this threshold). For this question, you can use a\n",
    "fixed step size in your implementation. Test your gradient descent procedure on two functions\n",
    "with the parameters provided by us in parametersp1.txt (for data files, we also provide basic\n",
    "reading scripts for MATLAB and Python): the negative of a Gaussian function and a quadratic\n",
    "bowl. Discuss (and illustrate) the effect of the choice of starting guess, the step size, and the\n",
    "convergence criterion on the resulting solution, as well as how the norm of the gradient evolves\n",
    "through the iteration.\n",
    "\n",
    "Things to Do:\n",
    "\n",
    "1. Test gradient descent procedure on the given functions and parameteres\n",
    "\n",
    "2. Study the effect of the choice of\n",
    "    1. starting guess\n",
    "    2. step size\n",
    "    3. convergence criteria\n",
    "3. Study how the norm of the gradient evolves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian deriv:  gaussian:  1.96348219951e-05\n",
      "[[  1.41415671e-06   0.00000000e+00]\n",
      " [  0.00000000e+00   2.02506778e-06]]\n",
      "gaussian:  1.96348219951e-05\n",
      "gaussian deriv:  gaussian:  1.96348219951e-05\n",
      "[[  1.41415671e-06   0.00000000e+00]\n",
      " [  0.00000000e+00   2.02506778e-06]]\n",
      "gaussian:  1.96348219951e-05\n",
      "objective fun gaussian:  [[  6.09399965e-06   3.07935306e-05]\n",
      " [  3.07935306e-05   6.32632520e-05]]\n",
      "[[  2.61880873e-05   1.12539540e-04]\n",
      " [  1.12539540e-04   8.43778244e-05]]\n",
      "gaussian:  [[  6.09399965e-06   3.07935306e-05]\n",
      " [  3.07935306e-05   6.32632520e-05]]\n",
      "gaussian:  1.96348219951e-05\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-98cbc2a5c8ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m                                                                                             \u001b[0minitial_guess\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                                                                                             \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                                                                                             convergence = 1e-04)\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mbest_guess\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Documents\\6867\\6867-Project1\\P1\\gradientDescent.py\u001b[0m in \u001b[0;36mgradientDescent\u001b[1;34m(objective_fn, gradient_fn, initial_guess, step_size, convergence)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'objective fun'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjective_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_new\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mobjective_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mconvergence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mconverged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Load parameters\n",
    "gaussMean,gaussCov,quadBowlA,quadBowlb = params.getData()\n",
    "\n",
    "# Test implementation of gradient descent on Gaussian\n",
    "\n",
    "objective_fn = lambda x : gd.computeGaussian(x, gaussMean, gaussCov)\n",
    "gradient_fn = lambda x: gd.differentiateGaussian(x, gaussMean, gaussCov)\n",
    "                                                                                            \n",
    "def testImplementation():\n",
    "    return None \n",
    "\n",
    "\n",
    "best_guess, best_value, guess_evolution, fxn_evolution, norm_evolution = gd.gradientDescent(objective_fn,\n",
    "                                                                                            gradient_fn,\n",
    "                                                                                            initial_guess= [np.random.randint(0,100),np.random.randint(0,100)], \n",
    "                                                                                            step_size=0.01,\n",
    "                                                                                            convergence = 1e-04)\n",
    "\n",
    "print best_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print fxn_evolution\n",
    "print norm_evolution\n",
    "\n",
    "# Plot how the norm changes over time \n",
    "\n",
    "# Plot how the function changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
