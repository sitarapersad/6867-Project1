{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEACAYAAACgS0HpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x83076a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas \n",
    "import gradientDescent as gd\n",
    "import loadParametersP1 as params\n",
    "import loadFittingDataP1 as fitData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implement a basic gradient descent procedure to minimize scalar functions of a vector argument.\n",
    "Write it generically, so that you can easily specify the objective function and the function\n",
    "to compute the gradient. You should be able to specify the initial guess, the step size (or learning\n",
    "rate) and the convergence criterion (e.g., a threshold such that the algorithm terminates\n",
    "when the difference in objective function value on two successive steps is below this threshold\n",
    "or when the norm of the gradient is below this threshold). For this question, you can use a\n",
    "fixed step size in your implementation. Test your gradient descent procedure on two functions\n",
    "with the parameters provided by us in parametersp1.txt (for data files, we also provide basic\n",
    "reading scripts for MATLAB and Python): the negative of a Gaussian function and a quadratic\n",
    "bowl. Discuss (and illustrate) the effect of the choice of starting guess, the step size, and the\n",
    "convergence criterion on the resulting solution, as well as how the norm of the gradient evolves\n",
    "through the iteration.\n",
    "\n",
    "Things to Do:\n",
    "\n",
    "1. Test gradient descent procedure on the given functions and parameteres\n",
    "\n",
    "2. Study the effect of the choice of\n",
    "    1. starting guess\n",
    "    2. step size\n",
    "    3. convergence criteria\n",
    "3. Study how the norm of the gradient evolves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian converged to:  -0.000159154630261 with [ 10.06269399  10.00078367]  in  7518  iterations.\n"
     ]
    }
   ],
   "source": [
    "# Load parameters\n",
    "gaussMean,gaussCov,quadBowlA,quadBowlb = params.getData()\n",
    "\n",
    "# Test implementation of gradient descent on Gaussian function\n",
    "\n",
    "objective_fn = lambda x : gd.computeGaussian(x, gaussMean, gaussCov)\n",
    "gradient_fn = lambda x: gd.differentiateGaussian(x, gaussMean, gaussCov)\n",
    "                                                                                        \n",
    "best_guess, best_value, guess, fxn, grad_norm = gd.gradientDescent(objective_fn,\n",
    "                                                              gradient_fn,\n",
    "                                                              initial_guess= [np.random.randint(0,100),np.random.randint(0,100)], \n",
    "                                                              step_size=10000,\n",
    "                                                              convergence = 1e-12)\n",
    "\n",
    "num_iters = len(grad_norm)\n",
    "print 'Gaussian converged to: ', best_value, 'with', best_guess, ' in ', num_iters, ' iterations.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolution of gradient norm\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEACAYAAAD8wQLNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9e9b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolution of function value\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEACAYAAABs0nsCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa0f8e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot how the norm changes over time \n",
    "print 'Evolution of gradient norm'#, norm\n",
    "pl.plot(range(num_iters), grad_norm)\n",
    "pl.show()\n",
    "\n",
    "# Plot how the function value changes over time\n",
    "print 'Evolution of function value'\n",
    "pl.plot(range(num_iters), fxn)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, test the implementation of the quadratic bowl using the given parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Bowl converged to:  -21333.3333388 [ 26.6858884   26.64744495]  in  140  iterations.\n"
     ]
    }
   ],
   "source": [
    "# Load parameters\n",
    "gaussMean,gaussCov,quadBowlA,quadBowlb = params.getData()\n",
    "\n",
    "# Test implementation of gradient descent on the Quadratic Bowl\n",
    "\n",
    "objective_fn = lambda x : gd.computeQuadBowl(x,quadBowlA,quadBowlb)\n",
    "gradient_fn = lambda x: gd.differentiateQuadBowl(x, quadBowlA,quadBowlb)\n",
    "\n",
    "best_guess, best_value, guess, fxn, norm = gd.gradientDescent(objective_fn,\n",
    "                                                              gradient_fn,\n",
    "                                                              initial_guess= [np.random.randint(-100,100),np.random.randint(-100,100)], \n",
    "                                                              step_size=0.01,\n",
    "                                                              convergence = 1e-6)\n",
    "\n",
    "num_iters = len(norm)\n",
    "print 'Quadratic Bowl converged to: ', best_value, best_guess, ' in ', num_iters, ' iterations.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot how the norm changes over time \n",
    "print 'Evolution of gradient norm'#, norm\n",
    "pl.plot(range(num_iters), norm)\n",
    "pl.show()\n",
    "\n",
    "# Plot how the function value changes over time\n",
    "print 'Evolution of function value'\n",
    "pl.plot(range(num_iters), fxn)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of starting guess, step size and convergence criteria\n",
    "Discuss (and illustrate) the effect of the choice of starting guess, the step size, and the\n",
    "convergence criterion on the resulting solution, as well as how the norm of the gradient evolves\n",
    "through the iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test the effect of the step size on the number of iterations to convergence and on the solution converged to\n",
    "\n",
    "\n",
    "def test_step(step_size):\n",
    "    best_guess, best_value, guess, fxn, norm = gd.gradientDescent(objective_fn,\n",
    "                                                              gradient_fn,\n",
    "                                                              initial_guess= [np.random.randint(-100,100),np.random.randint(-100,100)], \n",
    "                                                              step_size=step_size,\n",
    "                                                              convergence = 1e-10)\n",
    "    return best_value, len(fxn) #function value, number iterations\n",
    "\n",
    "step_sizes = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "values= []\n",
    "iters = []\n",
    "\n",
    "for step_size in step_sizes:\n",
    "    print 'Ran for ', step_size\n",
    "    val, its = test_step(step_size)\n",
    "    values.append(val)\n",
    "    iters.append(its)\n",
    "    \n",
    "# Plot the variation in convergence value as a function of step_size\n",
    "print 'Variation In Convergence Value'\n",
    "pl.plot(step_size, values)\n",
    "pl.show()\n",
    "# Plot the variation in number of iterations as a function of step_size\n",
    "print 'Variation In Convergence Value'\n",
    "pl.plot(step_size, iters)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the effect of the convergence criteria on the number of iterations to convergence and on the solution converged to\n",
    "\n",
    "def test_convergence(rate):\n",
    "    best_guess, best_value, guess, fxn, norm = gd.gradientDescent(objective_fn,\n",
    "                                                              gradient_fn,\n",
    "                                                              initial_guess= [np.random.randint(-100,100),np.random.randint(-100,100)], \n",
    "                                                              step_size= 1000,\n",
    "                                                              convergence = rate)\n",
    "    return best_value, len(fxn) #function value, number iterations\n",
    "\n",
    "criteria = [1e-10, 1e-8, 1e-6, 1e-4, 1e-2, 1, 10]\n",
    "\n",
    "values= []\n",
    "iters = []\n",
    "\n",
    "for rate in criteria:\n",
    "    val, its = test_convergence(rate)\n",
    "    values.append(val)\n",
    "    iters.append(its)\n",
    "    \n",
    "# Plot the variation in convergence value as a function of step_size\n",
    "\n",
    "# Plot the variation in number of iterations as a function of step_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the effect of the starting guess on the number of iterations to convergence and on the solution converged to\n",
    "\n",
    "TO DO -  FIX THIS PART\n",
    "\n",
    "def test_convergence(rate):\n",
    "    best_guess, best_value, guess, fxn, norm = gd.gradientDescent(objective_fn,\n",
    "                                                              gradient_fn,\n",
    "                                                              initial_guess= [np.random.randint(-100,100),np.random.randint(-100,100)], \n",
    "                                                              step_size= 1000,\n",
    "                                                              convergence = rate)\n",
    "    return best_value, len(fxn) #function value, number iterations\n",
    "\n",
    "criteria = [1e-10, 1e-8, 1e-6, 1e-4, 1e-2, 1, 10]\n",
    "\n",
    "values= []\n",
    "iters = []\n",
    "\n",
    "for rate in criteria:\n",
    "    val, its = test_convergence(rate)\n",
    "    values.append(val)\n",
    "    iters.append(its)\n",
    "    \n",
    "# Plot the variation in convergence value as a function of step_size\n",
    "\n",
    "# Plot the variation in number of iterations as a function of step_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The gradient function may not always look as simple and clean as the ones provided above. \n",
    "A common way to check if one’s gradient evaluation is correct or not is to use the central difference\n",
    "approximation (see the “Finite difference” article in Wikipedia) to numerically evaluate\n",
    "the gradient at various points. Write code to approximate the gradient of a function numerically\n",
    "at a given point using this method. Verify the gradient values on the functions you used\n",
    "in the question above by comparing the closed-form and numerical gradients at various points.\n",
    "Discuss the effect of changing the difference step (or $\\delta$) on the accuracy of the gradient\n",
    "evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For various values of delta, calculate the gradient using the closed form and the approximation of Gaussian\n",
    "# use 2-D points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "0-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9bbc875880b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifferentiateGaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mapprox_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeGaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mapprox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximateGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapprox_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Documents\\6867\\6867-Project1\\P1\\gradientDescent.py\u001b[0m in \u001b[0;36mdifferentiateGaussian\u001b[1;34m(x, mu, sigma)\u001b[0m\n\u001b[0;32m     52\u001b[0m     '''\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# print 'gaussian deriv: ',computeGaussian(x, mu, sigma)*np.dot(np.linalg.inv(sigma),(x-mu)), 'end'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcomputeGaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcomputeQuadBowl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Documents\\6867\\6867-Project1\\P1\\gradientDescent.py\u001b[0m in \u001b[0;36mcomputeGaussian\u001b[1;34m(x, mu, sigma)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mexponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mexponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mexponent\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Anaconda2\\lib\\site-packages\\numpy\\linalg\\linalg.pyc\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \"\"\"\n\u001b[0;32m    515\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[0m_assertNdSquareness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Anaconda2\\lib\\site-packages\\numpy\\linalg\\linalg.pyc\u001b[0m in \u001b[0;36m_assertRankAtLeast2\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             raise LinAlgError('%d-dimensional array given. Array must be '\n\u001b[1;32m--> 202\u001b[1;33m                     'at least two-dimensional' % len(a.shape))\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_assertSquareness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 0-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "# For various values of delta, calculate the gradient using the closed form and the approximation of Gaussian\n",
    "# Use 1-D points for simpler visualization\n",
    "\n",
    "diffs = []\n",
    "deltas = [1e-8, 1e-6, 1e-4, 1e-2,1,10,1e2,1e4]\n",
    "\n",
    "x = 1\n",
    "mu = 0\n",
    "sigma = 1\n",
    "\n",
    "for d in deltas:\n",
    "    point = -100 + 200* np.random.random()\n",
    "\n",
    "    true = gd.differentiateGaussian(point, mu, sigma)\n",
    "    approx_fn = lambda x: gd.computeGaussian(x, mu, sigma)\n",
    "    approx = gd.approximateGradient(point, approx_fn, d)\n",
    "    \n",
    "    diffs.append(true-approx)\n",
    "    \n",
    "#Plot the difference in gradient value vs delta value\n",
    "pl.plot(np.log(deltas), diffs, '-bo')\n",
    "pl.ylabel('true gradient - approx gradient')\n",
    "pl.xlabel('log $ \\delta$')\n",
    "pl.title('Effect of $\\delta$ on the gradient approximation')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,2) and (1,) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-57405fe0e931>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifferentiateQuadBowl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquadBowlA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquadBowlb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mapprox_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeQuadBowl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquadBowlA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquadBowlb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mapprox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximateGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapprox_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdiffs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mapprox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Documents\\6867\\6867-Project1\\P1\\gradientDescent.py\u001b[0m in \u001b[0;36mapproximateGradient\u001b[1;34m(point, approx_fn, delta)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mgradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapprox_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mapprox_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdelta_val\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-57405fe0e931>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifferentiateQuadBowl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquadBowlA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquadBowlb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mapprox_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeQuadBowl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquadBowlA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquadBowlb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mapprox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapproximateGradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapprox_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Documents\\6867\\6867-Project1\\P1\\gradientDescent.py\u001b[0m in \u001b[0;36mcomputeQuadBowl\u001b[1;34m(x, A, b)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0mof\u001b[0m \u001b[0mx\u001b[0m \u001b[0mwhich\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     '''\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdifferentiateQuadBowl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,2) and (1,) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# For various values of delta, calculate the gradient using the closed form and the approximation of Quadratic Bowl\n",
    "# Use 1-D points for simpler visualization\n",
    "\n",
    "diffs = []\n",
    "deltas = [1e-8, 1e-6, 1e-4, 1e-2,1,10,1e2,1e4]\n",
    "\n",
    "for d in deltas:\n",
    "    point = -100 + 200* np.random.random()\n",
    "\n",
    "    true = gd.differentiateQuadBowl(point,quadBowlA,quadBowlb)\n",
    "    approx_fn = lambda x: gd.computeQuadBowl(x,quadBowlA,quadBowlb)\n",
    "    approx = gd.approximateGradient(point, approx_fn, d)\n",
    "    \n",
    "    diffs.append(true-approx)\n",
    "\n",
    "#Plot the difference in gradient value vs delta value\n",
    "pl.plot(x=deltas, y=diffs)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. In machine learning and statistical estimation context, batch gradient descent uses samples from the full training set for each parameter update. \n",
    "Thus, each iteration would be slow for a large dataset. In addition, the native form of batch gradient descent does not provide a way to incorporate new data efficiently (i.e., in an online setting). Stochastic gradient descent (SGD)\n",
    "addresses these problems by using stochastic approximation on the gradient term (See Bishop\n",
    "3.1.3, 5.2.4 and Wikipedia). In this question, we will use both batch gradient descent and SGD\n",
    "on a least square fitting problem.\n",
    "The dataset is provided in fittingdatap1 x.txt and fittingdatap1 y.txt. Each row of X and\n",
    "y represents a single data sample pair (x(i), y(i)) and your goal is to find a coefficient vector θ\n",
    "that minimizes the least square error of $J(θ) = ||X\\cdotθ − y||^2$. In this question, you don’t need to augment X\n",
    "with 1’s as we did in the lecture. Notice that J(θ) is natively a function over the whole dataset\n",
    "and there is a closed-form solution to this problem (Bishop Equation (3.15)), which would be\n",
    "useful for checking your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Use batch gradient descent on J(θ) with a fixed step size. This would be the case where the\n",
    "gradient of the cost function for the entire training dataset is used in each parameter update.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (10,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7f80dfcbd245>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m                                                               \u001b[0minitial_guess\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                                                               \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                                                               convergence = 1e-4)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Least squares converged to: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_guess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Documents\\6867\\6867-Project1\\P1\\gradientDescent.pyc\u001b[0m in \u001b[0;36mgradientDescent\u001b[1;34m(objective_fn, gradient_fn, initial_guess, step_size, convergence)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mw_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgradient_fn\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             \u001b[0mw_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m             \u001b[0mnorm_evolution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7f80dfcbd245>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(theta)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mobjective_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeSquaredLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgradient_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifferentiateSquaredLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m best_guess, best_value, guess, fxn, norm = gd.gradientDescent(objective_fn,\n",
      "\u001b[1;32mC:\\Users\\Sitara\\Documents\\6867\\6867-Project1\\P1\\gradientDescent.pyc\u001b[0m in \u001b[0;36mdifferentiateSquaredLoss\u001b[1;34m(X, Y, theta)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mgradient\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (10,) "
     ]
    }
   ],
   "source": [
    "# Run batch gradient descent with a squared error objective function\n",
    "\n",
    "#Load data set\n",
    "X, Y = fitData.getData()\n",
    "intial_guess=np.zeros(len(X[0]))\n",
    "initial_guess.fill(np.random.random())\n",
    "\n",
    "objective_fn = lambda theta : gd.computeSquaredLoss(X, Y, theta)\n",
    "gradient_fn = lambda theta: gd.differentiateSquaredLoss(X,Y,theta)\n",
    "                                                                                        \n",
    "best_guess, best_value, guess, fxn, norm = gd.gradientDescent(objective_fn,\n",
    "                                                              gradient_fn,\n",
    "                                                              initial_guess= initial_guess, \n",
    "                                                              step_size=0.1,\n",
    "                                                              convergence = 1e-4)\n",
    "\n",
    "print 'Least squares converged to: ', best_guess, best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In contrast to batch gradient descent, which uses all training data in every parameter update,\n",
    "SGD performs a parameter update based on a single training example:\n",
    "θt+1 = θt − ηt∇θJ(θt\n",
    "; x\n",
    "(i)\n",
    ", y(i)\n",
    "),\n",
    "where ηt\n",
    "is the learning rate for each iteration t = 1, 2, ... and J(θt\n",
    "; x\n",
    "(i)\n",
    ", y(i)\n",
    ") = (x\n",
    "(i)T\n",
    "θt−y\n",
    "(i)\n",
    ")\n",
    "2\n",
    "is\n",
    "the objective function in terms of a single data sample. Write a general procedure that performs\n",
    "SGD on this dataset. You should first derive the point-wise (with respect to a single data\n",
    "sample) gradient function, ∇θJ(θt\n",
    "; x\n",
    "(i)\n",
    ", y(i)\n",
    "). Then write a procedure to perform parameter\n",
    "update by iterating through the samples in the dataset for some number of rounds until a\n",
    "stopping criterion is reached (such as convergence of the full objective function over all data\n",
    "points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Compare the behavior of the two implementations in terms of accuracy and number of evaluations\n",
    "of the point-wise gradient, ∇θJ(θt\n",
    "; x\n",
    "(i)\n",
    ", y(i)\n",
    "). That is, each iteration of batch gradient\n",
    "descent takes n (the number of total samples) evaluations of the point-wise gradients, whereas\n",
    "each iteration of SGD takes one evaluation of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-664a1d1b6d44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run stochastic gradient descent on the given dataset then compare it with the previous batch gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m best_guess, best_value, guess, fxn, grad_norm = gd.stochasticGradientDescent(x = X,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                                      \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                      \u001b[0mobjective_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                      \u001b[0mgradient_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Run stochastic gradient descent on the given dataset then compare it with the previous batch gradient descent\n",
    "best_guess, best_value, guess, fxn, grad_norm = gd.stochasticGradientDescent(x = X,\n",
    "                                                                     y = Y, \n",
    "                                                                     objective_fn = objective_fn,\n",
    "                                                                     gradient_fn = gradient_fn,\n",
    "                                                                     initial_guess= [np.random.randint(0,100),np.random.randint(0,100)], \n",
    "                                                                     step_size=1000,\n",
    "                                                                     convergence = 1e-4)\n",
    "\n",
    "num_iters = len(grad_norm)\n",
    "print 'Stochastic gradient descent converged to ', best_value, ' in ', num_iters, ' iterations'\n",
    "\n",
    "# Plot how the norm changes over time \n",
    "pl.plot(range(num_iters), grad_norm)\n",
    "pl.show()\n",
    "\n",
    "# Plot how the function value changes over time\n",
    "pl.plot(range(num_iters), fxn)\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
